{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Hm22TjJ6Md",
        "outputId": "f9d54413-20de-45e4-95ea-7e8ec63429a1"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "model = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
        "ai_message = model.invoke(\"自己紹介してください\")\n",
        "print(ai_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-BVORfVSKe8",
        "outputId": "7b8f1e9a-3c08-4325-cab4-8bbe1bd9e4cc"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\"You are a helpful assistant.\"),\n",
        "    HumanMessage(\"こんにちは！私はジョンと言います\"),\n",
        "    AIMessage(content=\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
        "    HumanMessage(content=\"私の名前がわかりますか？\"),\n",
        "]\n",
        "\n",
        "ai_message = model.invoke(messages)\n",
        "print(ai_message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG8w6S7sKBDb",
        "outputId": "66c2ddcd-b7cb-4e28-e530-71a4a712b847"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(\"You are a helpful assistant.\"),\n",
        "    HumanMessage(\"こんにちは\"),\n",
        "]\n",
        "\n",
        "for chunk in model.stream(messages):\n",
        "  print(chunk.content, end=\"\",flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj6ySdQjRxYl",
        "outputId": "33cbcda1-8e8d-4c11-a6d9-625d5286d960"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"\"\"以下のレシピを考えてください。\n",
        "\n",
        "料理名: {dish}\"\"\")\n",
        "\n",
        "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
        "print(prompt_value.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jB_hxbd0idN",
        "outputId": "cd64fe1d-8899-471e-b7bd-6df86915af80"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
        "        (\"human\", \"{dish}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
        "print(prompt_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_eAo-n01zY8",
        "outputId": "867b9a5a-01d8-481e-ce64-ae1262bf3a34"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_value = prompt.invoke(\n",
        "    {\n",
        "        \"chat_history\": [\n",
        "            HumanMessage(content=\"こんにちは！私はジョンと言います！\"),\n",
        "            AIMessage(\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
        "        ],\n",
        "        \"input\": \"私の名前が分かりますか？\",\n",
        "    }\n",
        ")\n",
        "print(prompt_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IS2jIyF3a_L",
        "outputId": "272a6634-88ce-44b6-df81-3ff46ffee943"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "prompt = client.pull_prompt(\"oshima/recipe\")\n",
        "\n",
        "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
        "print(prompt_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "97ONM1jv4Ky-"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "  ingredients: list[str] = Field(description= \"ingredients of the dish\")\n",
        "  steps: list[str] = Field(description=\"Steps ti make the dish\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f3lGaDjk4CWx"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=Recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USxY-m-xnrmu",
        "outputId": "fa4317ab-dcca-4cb1-b67c-51c9ddb0ce6b"
      },
      "outputs": [],
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UlNnv_l7nyEo"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"ユーザーが入力した料理のレシピを考えてください。\\n\\n\"\n",
        "            \"{format_instructions}\",\n",
        "        ),\n",
        "        (\"human\", \"{dish}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_with_format_instructions = prompt.partial(\n",
        "    format_instructions=format_instructions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM_Dogaw2zdK",
        "outputId": "9e723288-50e2-4e3d-af81-eeb026f12444"
      },
      "outputs": [],
      "source": [
        "prompt_value = prompt_with_format_instructions.invoke({\"dish\": \"カレー\"})\n",
        "print(\"=== role: system ===\")\n",
        "print(prompt_value.messages[0].content)\n",
        "print(\"=== role: human ===\")\n",
        "print(prompt_value.messages[1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctPg3Ed43Kmp",
        "outputId": "33758bc8-be12-4f68-aaf1-b30f49ffcf88"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0)\n",
        "\n",
        "ai_message = model.invoke(prompt_value)\n",
        "print(ai_message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkGJbKSc4cdS"
      },
      "source": [
        "### StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jfIK9a43z4D",
        "outputId": "327244b3-caf9-47bd-98f2-26bb2a62a698"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "ai_message = AIMessage(content=\"こんにちは。私はAIアシスタントです\")\n",
        "output = output_parser.invoke(ai_message)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7ZXrPrN41qW"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\"ユーザーが入力した料理のレシピを教えてください。\"),\n",
        "        (\"human\", \"{dish}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\",temperature=0)\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "ai_message = chain.invoke({\"dish\":\"カレー\"})\n",
        "print(ai_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTTxKS3OfEhi",
        "outputId": "b42925d3-6937-4535-8557-b2c5ff9c3a37"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chain = prompt | model | StrOutputParser()\n",
        "output = chain.invoke({\"dish\":\"カレー\"})\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zAMJWKfs-xn0",
        "outputId": "87534848-f71c-4546-ba76-051f016135bd"
      },
      "outputs": [],
      "source": [
        "!pip install  GitPython==3.1.43"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsikC9bLiFbQ",
        "outputId": "ebe4b935-85fc-4846-e964-589f4d48c93d"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import GitLoader\n",
        "\n",
        "def file_filter(file_path: str) -> bool:\n",
        "    return file_path.endswith(\".md\")\n",
        "\n",
        "\n",
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
        "    repo_path=\"./langchain\",\n",
        "    branch=\"master\",\n",
        "    file_filter=file_filter,\n",
        ")\n",
        "\n",
        "raw_docs = loader.load()\n",
        "print(len(raw_docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "4NoBrMXY-vM9",
        "outputId": "430c3b10-9967-4a4a-ca04-7aaaef0b9a11"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain-text-splitters==0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f50gqmliB5Hq",
        "outputId": "3cfde6e5-409c-451d-c8dc-8fc9f3e4122a"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "docs = text_splitter.split_documents(raw_docs)\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g2zl0YSbDWv7"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaGtojWLEqqv",
        "outputId": "a19b3188-d211-4d4c-cf0e-3f7816fc69fd"
      },
      "outputs": [],
      "source": [
        "query = \"AWSのS3からデータを読み込むためのDocument loaderはありますか？\"\n",
        "\n",
        "vector = embeddings.embed_query(query)\n",
        "print(len(vector))\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIxWzlVFN3KE",
        "outputId": "a8c9ba09-b584-42e1-a60d-5283644b211a"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-chroma==0.1.4 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "tEeJ5uMQRu1d",
        "outputId": "f98e1dad-5c2d-46a1-c9f1-b62bd61e87ed"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(docs, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0zmLWljDxIn"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
